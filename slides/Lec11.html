<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>36-315 Lecture 11</title>
    <meta charset="utf-8" />
    <meta name="author" content="Professor Ron Yurko" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <script src="libs/clipboard/clipboard.min.js"></script>
    <link href="libs/xaringanExtra-clipboard/xaringanExtra-clipboard.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-clipboard/xaringanExtra-clipboard.js"></script>
    <script>window.xaringanExtraClipboard(null, {"button":"Copy Code","success":"Copied!","error":"Press Ctrl+C to Copy"})</script>
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# 36-315 Lecture 11
]
.subtitle[
## Inference with Linear Regression
]
.author[
### Professor Ron Yurko
]
.date[
### 2/22/2023
]

---









## Displaying trend lines: linear regression

.pull-left[


```r
penguins %&gt;%
  ggplot(aes(x = flipper_length_mm, 
             y = body_mass_g)) +
  geom_point(alpha = 0.5) + 
* geom_smooth(method = "lm")
```

- Displays `body_mass_g ~ flipper_length_mm` regression line

- Adds 95% confidence intervals by default

- Estimating the __conditional expectation__ of `body_mass_g` | `flipper_length_mm`, 

  - i.e., `\(\mathbb{E}[Y | X]\)`


]
.pull-right[

&lt;img src="figs/Lec11/unnamed-chunk-2-1.png" width="100%" /&gt;


]



---

## Statistical Model for Linear Regression

Linear regression assumes `\(Y_i \overset{iid}{\sim} N(\beta_0 + \beta_1 X_i, \sigma^2)\)`

- `\(\beta_0\)`: _intercept_ - population mean outcome when `\(X = 0\)`; i.e., `\(\mathbb{E}[Y | X = 0]\)`

- `\(\beta_1\)`: _slope_ - population mean _change_ in `\(Y\)` when `\(X\)` increases by 1

- `\(\beta_0\)` and `\(\beta_1\)` are parameters that must be estimated

--

The assumptions baked into this model are:

1. Normality

2. Equal variance

3. Independent errors

4. Linearity

5. Fixed `\(X\)`


---

## Assessing assumptions of linear regression

Linear regression assumes `\(Y_i \overset{iid}{\sim} N(\beta_0 + \beta_1 X_i, \sigma^2)\)`

- If this is true, then `\(Y_i - \hat{Y}_i \overset{iid}{\sim} N(0, \sigma^2)\)`

--

Plot residuals against `\(\hat{Y}_i\)`, __residuals vs fit__ plot

- Used to assess linearity, any divergence from mean 0

- Used to assess equal variance, i.e., if `\(\sigma^2\)` is homogenous across predictions/fits `\(\hat{Y}_i\)`

--

More difficult to assess the independence and fixed `\(X\)` assumptions

- Make these assumptions based on subject-matter knowledge

---

## Residual vs fit plots

.pull-left[


```r
lin_reg &lt;- 
* lm(body_mass_g ~ flipper_length_mm,
     data = penguins)

tibble(fits = fitted(lin_reg), 
       residuals = residuals(lin_reg)) %&gt;%
  ggplot(aes(x = fits, y = residuals)) +
  geom_point(alpha = 0.5) +
* geom_hline(yintercept = 0,
*            linetype = "dashed",
             color = "red")
```

Two things to look for:

1. Any trend around horizontal reference line?

2. Equal vertical spread?

]

.pull-right[

&lt;img src="figs/Lec11/unnamed-chunk-3-1.png" width="100%" /&gt;


]

---

## Residual vs fit plots

.pull-left[


```r
tibble(fits = fitted(lin_reg), 
       residuals = residuals(lin_reg)) %&gt;%
  ggplot(aes(x = fits, y = residuals)) +
  geom_point(alpha = 0.5) +
  geom_hline(yintercept = 0, 
             linetype = "dashed",
             color = "red") +
* geom_smooth()
```

Two things to look for:

1. Any trend around horizontal reference line? 

  - add `geom_smooth` to highlight this

2. Equal vertical spread?

]

.pull-right[

&lt;img src="figs/Lec11/unnamed-chunk-4-1.png" width="100%" /&gt;


]

---

## Examples of Residual-vs-Fit Plots



---

## More fun with `penguins`...

Lecture 11 Demo: Walk through an example of plotting/running different linear regression models

+ __Outcome__: bill depth (in mm)

+ __Covariates__: bill length (depth) and species 

Linear regression models we will consider:

1. `bill_depth_mm` ~ `bill_length_mm`

2. `bill_depth_mm` ~ `bill_length_mm` + `species`

3. `bill_depth_mm` ~ `bill_length_mm` + `species` + `bill_length_mm` `\(\times\)` `species`


---

## Model #1: 
### `bill_depth_mm` ~ `bill_length_mm`

&lt;img src="figs/Lec11/unnamed-chunk-5-1.png" width="100%" style="display: block; margin: auto;" /&gt;

---


```r
summary(lm(bill_depth_mm ~ bill_length_mm, data = penguins))
```

```
## 
## Call:
## lm(formula = bill_depth_mm ~ bill_length_mm, data = penguins)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.1381 -1.4263  0.0164  1.3841  4.5255 
## 
## Coefficients:
##                Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)    20.88547    0.84388  24.749  &lt; 2e-16 ***
## bill_length_mm -0.08502    0.01907  -4.459 1.12e-05 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 1.922 on 340 degrees of freedom
##   (2 observations deleted due to missingness)
## Multiple R-squared:  0.05525,	Adjusted R-squared:  0.05247 
## F-statistic: 19.88 on 1 and 340 DF,  p-value: 1.12e-05
```


---

## How are the intercept and slope estimated?

We have data `\((X_i, Y_i)\)`. Want to estimate `\(\beta_0\)` and `\(\beta_1\)`, where `\(\mathbb{E}[Y | X] = \beta_0 + \beta_1 X\)`

If we had `\(\hat{\beta}_0\)` and `\(\hat{\beta}_1\)`, then `\(\hat{Y}_i = \hat{\beta}_0 + \hat{\beta}_1 X_i\)`

--

The estimates `\(\hat{\beta}_0\)` and `\(\hat{\beta}_1\)` are obtained by solving

`$$\arg \min_{\beta_0,\beta_1} \sum_{i=1}^n (Y_i - \beta_0 - \beta_1 X_i)^2$$`

- Remember that `\(\hat{Y}_i = \hat{\beta}_0 + \hat{\beta}_1 X_i\)`, so the above is saying: "_Give me the `\(\hat{Y}_i\)` such that `\((Y_i - \hat{Y}_i)^2\)` is minimized, on average_"


The estimates `\(\hat{\beta}_0\)` and `\(\hat{\beta}_1\)` are:

`$$\hat{\beta}_1 = \frac{\sum_{i=1}^n (X_i - \bar{X})(Y_i - \bar{Y})}{\sum_{i=1}^n (X_i - \bar{X})^2} = \frac{\text{Cov}(X,Y)}{\text{Var}(X)} \\
            \hat{\beta}_0 = \bar{Y} - \hat{\beta}_1 \bar{X}$$`



---

## Assessing the Fit of Linear Regression


Intuitively, the more `\(X\)` and `\(Y\)` are correlated, the better the fit of the linear regression

Correlation is defined as

`$$\rho = \frac{\sum_{i=1}^n (X_i - \bar{X})(Y_i - \bar{Y})}{\sqrt{\sum_{i=1}^n (X_i - \bar{X})^2 \cdot \sum_{i=1}^n (Y_i - \bar{Y})^2}} = \frac{\text{Cov}(X,Y)}{ \sqrt{\text{Var}(X) \cdot \text{Var}(Y)} }$$`

- Correlation is just a standardized covariance, where `\(-1 \leq \rho \leq 1\)`.

- More generally, `\(R^2\)` measures the fraction of variability in the outcome _accounted by_ the covariates:

`$$R^2 = 1 - \frac{\sum_{i=1}^n (Y_i - \hat{Y}_i)^2}{\sum_{i=1}^n (Y_i - \bar{Y})^2} = 1 - \frac{\text{SS}_{\text{residuals}}}{\text{SS}_{\text{total}}}$$`

The higher `\(R^2\)`, the more the association. When linear regression has one covariate, `\(R = \rho\)`

---

## Multiple Linear Regression

Let's say we have a bunch of covariates `\(X_1,X_2,\dots,X_k\)`

The statistical model for multiple linear regression is

`$$Y_i \stackrel{iid}{\sim} N(\beta_0 + \beta_1 X_{i1} + \cdots + \beta_k X_{ik}, \sigma^2), \hspace{0.1in} \text{for all } i=1,\dots,n$$`

- Covariates can be quadratic, cubic, etc. forms of other covariates, so this is quite flexible

--

- How do we know when we've included the "right" covariates?

- The higher `\(R^2\)`, the more the association. So, maximize `\(R^2\)`?

- However, adding more covariates _always_ increases `\(R^2\)`. Better to look at "adjusted `\(R^2\)`", which accounts for this

- Also common: AIC and BIC (smaller is better). More on this later in the semester.

---

## Special Case - Categorical Variables

Can include categorical variables in multiple linear regression, but need to code them as "dummy variables" (i.e., indicator variables)

Say a categorical variable has `\(k \geq 2\)` levels. Need to create `\((k-1)\)` indicator variables, equal to 1 for _one_ category and 0 otherwise

__Important__: Categorical variable may be coded numerically (e.g., Agree = 1, Disagree = -1, Not Sure = 0)

- If you put this variable straight into `lm()`, it will fit a very different model!

---

## Understanding the Categorical Variables Example

Example: Penguins species: _Adelie_, _Chinstrap_, _Gentoo._ There are `\(k = 3\)` levels.

Create an indicator for _Chinstrap_ and _Gentoo_: `\(I_C\)` and `\(I_G\)`.  

- If `\(I_C = I_G = 0\)`, then the penguin must be _Adelie_

The statistical model would be `\(Y_i \stackrel{iid}{\sim} N(\beta_0 + \beta_C I_C + \beta_G I_G, \sigma^2)\)`

--

- `\(\beta_0\)`: Mean for _Adelie_

- `\(\beta_0 + \beta_C\)`: Mean for _Chinstrap_

- `\(\beta_0 + \beta_G\)`: Mean for _Gentoo_

--

- Significant `\(\beta_C\)` `\(\rightarrow\)` Chinstrap and Adelie are different

- Significant `\(\beta_G\)` `\(\rightarrow\)` Gentoo and Adelie are different

- How to compare Chinstrap and Gentoo? Need to fit a different model.

---

## Understanding Interactions (Categorical Example Again)

Say we also have a quantitative variable `\(X\)` (bill length). Consider two statistical models:

1. `\(Y_i \stackrel{iid}{\sim} N(\beta_0 + \beta_X X + \beta_C I_C + \beta_G I_G, \sigma^2)\)`

2. `\(Y_i \stackrel{iid}{\sim} N(\beta_0 + \beta_X X + \beta_C I_C + \beta_G I_G + \beta_{CX} I_C X + \beta_{GX} I_G X, \sigma^2)\)`

--

For Model 1...

- The intercept for Adelie is `\(\beta_0\)`; for Chinstrap it is `\(\beta_0 + \beta_C\)`; for Gentoo it is `\(\beta_0 + \beta_G\)`

- The slope for all species is `\(\beta_X\)`.

--

For Model 2...

- The intercept for Adelie is `\(\beta_0\)`; for Chinstrap it is `\(\beta_0 + \beta_C\)`; for Gentoo it is `\(\beta_0 + \beta_G\)`.

- The slope for Adelie is `\(\beta_X\)`; for Chinstrap it is `\(\beta_X + \beta_{CX}\)`; for Gentoo it is `\(\beta_X + \beta_{GX}\)`

--

Significant coefficient for categorical variables by themselves? Significantly different intercepts

Significant coefficient for interactions with categorical variables? Significantly different slopes

---

## Model #2: 
### `bill_depth_mm` ~ `bill_length_mm` + `species`

&lt;img src="figs/Lec11/unnamed-chunk-7-1.png" width="100%" style="display: block; margin: auto;" /&gt;

---


```r
summary(lm(bill_depth_mm ~ bill_length_mm + species, data = penguins))
```

```
## 
## Call:
## lm(formula = bill_depth_mm ~ bill_length_mm + species, data = penguins)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -2.4529 -0.6864 -0.0508  0.5519  3.5915 
## 
## Coefficients:
##                  Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)      10.59218    0.68302  15.508  &lt; 2e-16 ***
## bill_length_mm    0.19989    0.01749  11.427  &lt; 2e-16 ***
## speciesChinstrap -1.93319    0.22416  -8.624 2.55e-16 ***
## speciesGentoo    -5.10602    0.19142 -26.674  &lt; 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.9533 on 338 degrees of freedom
##   (2 observations deleted due to missingness)
## Multiple R-squared:  0.769,	Adjusted R-squared:  0.7669 
## F-statistic: 375.1 on 3 and 338 DF,  p-value: &lt; 2.2e-16
```


---

## Model #3: 
### `bill_depth_mm` ~ `bill_length_mm` + `species` + `bill_length_mm` `\(\times\)` `species`

&lt;img src="figs/Lec11/unnamed-chunk-9-1.png" width="100%" style="display: block; margin: auto;" /&gt;


---


```r
summary(lm(bill_depth_mm ~ bill_length_mm * species, data = penguins))
```

```
## 
## Call:
## lm(formula = bill_depth_mm ~ bill_length_mm * species, data = penguins)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -2.6574 -0.6675 -0.0524  0.5383  3.5032 
## 
## Coefficients:
##                                 Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)                     11.40912    1.13812  10.025  &lt; 2e-16 ***
## bill_length_mm                   0.17883    0.02927   6.110 2.76e-09 ***
## speciesChinstrap                -3.83998    2.05398  -1.870 0.062419 .  
## speciesGentoo                   -6.15812    1.75451  -3.510 0.000509 ***
## bill_length_mm:speciesChinstrap  0.04338    0.04558   0.952 0.341895    
## bill_length_mm:speciesGentoo     0.02601    0.04054   0.642 0.521590    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.9548 on 336 degrees of freedom
##   (2 observations deleted due to missingness)
## Multiple R-squared:  0.7697,	Adjusted R-squared:  0.7662 
## F-statistic: 224.5 on 5 and 336 DF,  p-value: &lt; 2.2e-16
```


---

## A Few Linear Regression Warnings


#### Simpson's Paradox

- There is a negative linear relationship between two variables but a positive linear relationship within every subpopulation

- In these cases, subgroup analysis is especially important

--

#### Is the intercept meaningful?

- Think about whether `\(X = 0\)` makes scientific sense for a particular variable before you interpret the intercept

--

#### Interpolation versus Extrapolation

- Interpolation is defined as prediction within the range of a variable

- Extrapolation is defined as prediction outside the range of a variable

- Generally speaking, interpolation is more reliable than extrapolation. (Less sensitive to model misspecification.)


---

## Extrapolation Example

&lt;img src="figs/Lec11/unnamed-chunk-11-1.png" width="100%" style="display: block; margin: auto;" /&gt;

---

## Extrapolation Example

&lt;img src="figs/Lec11/unnamed-chunk-12-1.png" width="100%" style="display: block; margin: auto;" /&gt;


---

## Extrapolation Example

&lt;img src="figs/Lec11/unnamed-chunk-13-1.png" width="100%" style="display: block; margin: auto;" /&gt;

---
class: center, middle

# Next time: Midsemester Review

Reminder: __HW4 due tonight!__ __Graphics critique due Feb 28th!__

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"slideNumberFormat": "%current%",
"highlightStyle": "github",
"highlightLines": true,
"ratio": "16:9",
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
