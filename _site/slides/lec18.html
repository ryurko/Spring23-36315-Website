<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>36-315 Lecture 18</title>
    <meta charset="utf-8" />
    <meta name="author" content="Professor Ron Yurko" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <script src="libs/clipboard/clipboard.min.js"></script>
    <link href="libs/xaringanExtra-clipboard/xaringanExtra-clipboard.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-clipboard/xaringanExtra-clipboard.js"></script>
    <script>window.xaringanExtraClipboard(null, {"button":"Copy Code","success":"Copied!","error":"Press Ctrl+C to Copy"})</script>
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# 36-315 Lecture 18
]
.subtitle[
## More PCA + Visualizations and Inference for Spatial Data
]
.author[
### Professor Ron Yurko
]
.date[
### 4/3/2023
]

---











## Principal Component Analysis (PCA)

$$
`\begin{pmatrix}
&amp; &amp; \text{really} &amp; &amp; \\
&amp; &amp; \text{wide} &amp; &amp; \\
&amp; &amp; \text{matrix} &amp; &amp;
\end{pmatrix}`
\rightarrow \text{matrix algebra stuff} \rightarrow 
`\begin{pmatrix}
\text{much}  \\
\text{thinner}  \\
\text{matrix} 
\end{pmatrix}`
$$

- Start with `\(n \times p\)` matrix of __correlated__ variables `\(\rightarrow\)` `\(n \times k\)` matrix of __uncorrelated__ variables

- Each of the `\(k\)` columns in the right-hand matrix are __principal components__, all uncorrelated with each other

- First column accounts for most variation in the data, second column for second-most variation, and so on

#### Intuition: first few principal components account for most of the variation in the data


---

## So what do we do with the principal components?

__The point__: given a dataset with `\(p\)` variables, we can find `\(k\)` variables `\((k &lt;&lt; p)\)` that account for most of the variation in the data


Note that the principal components are NOT easy to interpret - these are combinations of all variables

PCA is similar to MDS with these main differences:

1. MDS reduces a _distance_ matrix while PCA reduces a _data_ matrix

2. PCA has a principled way to choose `\(k\)`

3. Can visualize how the principal components are related to variables in data

---

## Working with PCA on Starbucks drinks

Use the `prcomp()` function (based on SVD) for PCA on __centered__ and __scaled__ data


```r
*starbucks_pca &lt;- prcomp(dplyr::select(starbucks, serv_size_m_l:caffeine_mg),
*                       center = TRUE, scale. = TRUE)
summary(starbucks_pca)
```

```
## Importance of components:
##                           PC1    PC2    PC3     PC4     PC5     PC6    PC7
## Standard deviation     2.4748 1.3074 1.0571 0.97919 0.67836 0.56399 0.4413
## Proportion of Variance 0.5568 0.1554 0.1016 0.08716 0.04183 0.02892 0.0177
## Cumulative Proportion  0.5568 0.7122 0.8138 0.90093 0.94276 0.97168 0.9894
##                            PC8     PC9    PC10    PC11
## Standard deviation     0.28123 0.16874 0.08702 0.04048
## Proportion of Variance 0.00719 0.00259 0.00069 0.00015
## Cumulative Proportion  0.99657 0.99916 0.99985 1.00000
```

---

## Computing Principal Components

Extract the matrix of principal components `\(\boldsymbol{Z} = XV\)` (dimension of `\(\boldsymbol{Z}\)` will match original data)


```r
starbucks_pc_matrix &lt;- starbucks_pca$x
head(starbucks_pc_matrix)
```

```
##            PC1        PC2        PC3           PC4         PC5         PC6
## [1,] -3.766852 -1.0023657  0.2482698 -0.1521871448  0.24739830 -0.11365847
## [2,] -3.633234 -0.6946439  1.2059943 -0.3720566566  0.06052789 -0.06406410
## [3,] -3.518063 -0.3981399  2.2165170 -0.5967175941 -0.13122572 -0.01937237
## [4,] -3.412061 -0.1067045  3.3741594 -0.8490378243 -0.26095965 -0.00899485
## [5,] -3.721426 -0.9868147 -1.0705094  0.0949330091 -0.27181508  0.17491809
## [6,] -3.564899 -0.6712499 -0.7779083 -0.0003019903 -0.72054963  0.37005543
##              PC7         PC8        PC9        PC10         PC11
## [1,] -0.02812472 0.006489978 0.05145094 -0.06678083 -0.019741873
## [2,]  0.05460952 0.021148978 0.07094211 -0.08080545 -0.023480029
## [3,]  0.09050806 0.031575955 0.08901403 -0.09389227 -0.028669251
## [4,]  0.11585507 0.037521689 0.11287190 -0.11582260 -0.034691142
## [5,]  0.07009414 0.037736197 0.02892317 -0.03631676 -0.005775410
## [6,]  0.20236484 0.068154160 0.03705252 -0.03497690 -0.002469611
```

Columns are uncorrelated, such that Var( `\(Z_1\)` ) `\(&gt;\)` Var( `\(Z_2\)` ) `\(&gt; \dots &gt;\)` Var( `\(Z_p\)` ) - can start with a scatterplot of `\(Z_1, Z_2\)`

---

## Starbucks drinks: PC1 and PC2

.pull-left[

```r
starbucks &lt;- starbucks %&gt;%
  mutate(pc1 = starbucks_pc_matrix[,1], 
         pc2 = starbucks_pc_matrix[,2])
starbucks %&gt;%
  ggplot(aes(x = pc1, y = pc2)) +
  geom_point(alpha = 0.5) +
  labs(x = "PC 1", y = "PC 2")
```

- __Look familiar?__

- Principal components are not interpretable, but we can add a __biplot__ with arrows showing the linear relationship between one variable and other variables

]

.pull-right[
&lt;img src="figs/lec18/unnamed-chunk-4-1.png" width="100%" /&gt;

]

---

## Making PCs interpretable with biplots ([`factoextra`](http://www.sthda.com/english/wiki/factoextra-r-package-easy-multivariate-data-analyses-and-elegant-visualization))

.pull-left[



```r
library(factoextra)
# Designate to only label the variables:
*fviz_pca_biplot(
* starbucks_pca, label = "var",
  # Change the alpha for observations 
  # which is represented by ind
  alpha.ind = .25,
  # Modify the alpha for variables (var):
  alpha.var = .75,
  col.var = "darkblue")
```

- Arrow direction: "as the variable increases..."

- Arrow angles: correlation

  - 90 degrees means uncorrelated
  - `\(&lt; 90\)` means positively correlated
  - `\(&gt; 90\)` means negatively correlated
  
- Arrow length: strength of relationship with PCs

]
.pull-right[
&lt;img src="figs/lec18/unnamed-chunk-5-1.png" width="100%" /&gt;

]

---

## How many principal components to use?

#### Intuition: Additional principal components will add smaller and smaller variance

- Keep adding components until the added variance _drops off_


```r
summary(starbucks_pca)
```

```
## Importance of components:
##                           PC1    PC2    PC3     PC4     PC5     PC6    PC7
## Standard deviation     2.4748 1.3074 1.0571 0.97919 0.67836 0.56399 0.4413
## Proportion of Variance 0.5568 0.1554 0.1016 0.08716 0.04183 0.02892 0.0177
## Cumulative Proportion  0.5568 0.7122 0.8138 0.90093 0.94276 0.97168 0.9894
##                            PC8     PC9    PC10    PC11
## Standard deviation     0.28123 0.16874 0.08702 0.04048
## Proportion of Variance 0.00719 0.00259 0.00069 0.00015
## Cumulative Proportion  0.99657 0.99916 0.99985 1.00000
```

---

## Create scree plot (aka "elbow plot") to choose


```r
*fviz_eig(starbucks_pca, addlabels = TRUE) +
  geom_hline(yintercept = 100 * (1 / ncol(starbucks_pca$x)), linetype = "dashed", color = "darkred")
```

&lt;img src="figs/lec18/scree-plot-1.png" width="80%" style="display: block; margin: auto;" /&gt;

- Number of dimensions on x-axis, proportion of variance on y-axis

- _Rule of thumb_: horizontal line at `\(1/p\)` (__Why?__)

---

## Main Takeaways

#### It's really hard to visualize many dimensions at the same time

- Often, it makes a lot of sense to choose 2-4 of the "most important dimensions" and just plot those

#### PCA is a very common way to define "most important dimensions"

#### PCA provides the linear combinations of variables that capture the most variation in the data.

#### Common to plot the first two principal components in a scatterplot, and see if subjects cluster based on other variables (similar to MDS)

#### Especially useful to plot principal components with a biplot (e.g., with `factoextra`)

- Adds interpretability to the principal components, and helps you see relationships among the variables


---




# How should we think about spatial data?

- Typically location is measured with __latitude__ / __longitude__ (2D)

- __Latitude__: Measures North / South (the "y-axis")

  - Range is `\((-90^{\circ}, 90^{\circ})\)`
  
  - Measures degrees from the equator `\((0^{\circ})\)`
  
  - `\((-90^{\circ}, 0^{\circ})\)` = southern hemisphere 
  
  - `\((0^{\circ}, 90^{\circ})\)` = northern hemisphere 
  
--

- __Longitude__: Measures East/West (the "x-axis")

  - Range is `\((-180^{\circ}, 180^{\circ})\)`
  
  - Measures degrees from the prime meridian `\((0^{\circ})\)` in Greenwich, England
  
  - `\((-180^{\circ}, 0^{\circ})\)` = eastern hemisphere
  
  - `\((0^{\circ}, 180^{\circ})\)` = western hemisphere


---

# Latitude and Longitude


&lt;img src="https://c.tadst.com/gfx/1200x630/longitude-and-latitude-simple.png?1" width="80%" style="display: block; margin: auto;" /&gt;

---

# Map Projections

- Earth is a 3D object, but maps are 2D objects

- __Map projections__: Transformation of the lat / long coordinates on a sphere (the earth) to a 2D plane
  
- There are many different projections - each will distort the map in different ways.

- The most common projections are:

  - [Mercator](https://en.wikipedia.org/wiki/Mercator_projection)
  - [Robinson](https://en.wikipedia.org/wiki/Robinson_projection)
  - [Conic](http://www.geo.hunter.cuny.edu/~jochen/gtech201/lectures/lec6concepts/Map%20coordinate%20systems/Conic%20projections.htm#:~:text=Conic%20projections%20are%20created%20by,a%20developable%20map%20projection%20surface.)
  - [Cylindrical](https://en.wikipedia.org/wiki/Map_projection#Cylindrical)
  - [Planar](http://www.geo.hunter.cuny.edu/~jochen/gtech201/lectures/lec6concepts/Map%20coordinate%20systems/Planar%20projections.htm)
  - [Interrupted projections](https://en.wikipedia.org/wiki/Interruption_(map_projection))


---

# Mercator Projection (1500s)


&lt;img src="https://upload.wikimedia.org/wikipedia/commons/thumb/7/73/Mercator_projection_Square.JPG/700px-Mercator_projection_Square.JPG" width="60%" style="display: block; margin: auto;" /&gt;


---

# Mercator Projection (Tissot indicatrix)


&lt;img src="https://upload.wikimedia.org/wikipedia/commons/thumb/0/02/Mercator_with_Tissot%27s_Indicatrices_of_Distortion.svg/700px-Mercator_with_Tissot%27s_Indicatrices_of_Distortion.svg.png" width="60%" style="display: block; margin: auto;" /&gt;


---

# Robinson Projection (Standard from 1963-1998)

&lt;img src="https://upload.wikimedia.org/wikipedia/commons/thumb/9/96/Robinson_projection_SW.jpg/700px-Robinson_projection_SW.jpg" width="70%" style="display: block; margin: auto;" /&gt;


---

# Robinson Projection (Tissot indicatrix)


&lt;img src="https://upload.wikimedia.org/wikipedia/commons/thumb/7/7a/Robinson_with_Tissot%27s_Indicatrices_of_Distortion.svg/700px-Robinson_with_Tissot%27s_Indicatrices_of_Distortion.svg.png" width="70%" style="display: block; margin: auto;" /&gt;


---

# Winkel Tripel Projection (proposed 1921, now the standard)

&lt;img src="https://upload.wikimedia.org/wikipedia/commons/thumb/9/91/Winkel_triple_projection_SW.jpg/660px-Winkel_triple_projection_SW.jpg" width="60%" style="display: block; margin: auto;" /&gt;

---

# Winkel Tripel Projection (Tissot indicatrix)

&lt;img src="https://upload.wikimedia.org/wikipedia/commons/thumb/3/36/Winkel_Tripel_with_Tissot%27s_Indicatrices_of_Distortion.svg/660px-Winkel_Tripel_with_Tissot%27s_Indicatrices_of_Distortion.svg.png" width="60%" style="display: block; margin: auto;" /&gt;

---

# And many more... (see [xkcd comic](https://xkcd.com/977/))

&lt;img src="https://i.pinimg.com/originals/2d/03/cf/2d03cffa216afb23fa50fb07fc1221b1.jpg" width="60%" style="display: block; margin: auto;" /&gt;


---

## Visualizing spatial data on maps using [`ggmap`](https://cran.r-project.org/web/packages/ggmap/readme/README.html)

.pull-left[


```r
library(ggmap)
# First, we'll draw a "box" around the US
# (in terms of latitude and longitude)
US &lt;- c(left = -125, bottom = 10, 
        right = -67, top = 49)
map &lt;- get_stamenmap(US, zoom = 5, 
                     maptype = "toner-lite")

# Visualize the basic map
*ggmap(map)
```

- Draw map based on lat / lon coordinates

- Put the box into `get_stamenmap()` to access [Stamen Maps](http://maps.stamen.com/#terrain/12/37.7706/-122.3782)

- Draw the map using `ggmap()` to serve as base

]

.pull-right[
&lt;img src="figs/lec18/unnamed-chunk-16-1.png" width="100%" /&gt;

]

---

# Three main types of spatial data


1. __Point Pattern Data__: lat-long coordinates where events have occurred

2. __Point-Referenced data__: Latitude-longitude (lat-long) coordinates as well as one or more variables specific to those coordinates.

3. __Areal Data__: Geographic regions with one or more variables associated with those regions.

--

- Each type is structured differently within a dataset

- Each type requires a different kind of graph(s)

--

We're going to review each type of data. Then, we're going to demonstrate how to plot these different data types

+ __Today: Point-referenced and point pattern__

+ Wednesday: Areal data

---

# Point-Pattern data

- __Point Pattern Data__: lat-long coordinates where events have occurred

- __Point pattern data simply records the lat-long of events__; thus, there are only two columns

- Again, latitude and longitude are represented with dots, sometimes called a dot or bubble map.

--

- The goal is to understand how the __density__ of events varies across space

- The density of the dots can also be visualized (e.g., with contours)

  - __Use methods we've discussed before for visualizing 2D joint distribution__


---

&lt;img src="https://static01.nyt.com/images/2020/09/10/learning/TotalCovidMap-LN/TotalCovidMap-LN-superJumbo.png?quality=75&amp;auto=webp" width="80%" style="display: block; margin: auto;" /&gt;


---

# Point-Referenced data

- __Point-Referenced data__: Latitude-longitude (lat-long) coordinates as well as one or more variables specific to those coordinates

- Point-referenced data will have the following form:


```r
airports %&gt;% dplyr::select(lat, lon, altitude, n_depart, n_arrive, name) %&gt;% slice(1:3)
```

```
## # A tibble: 3 × 6
##     lat   lon altitude n_depart n_arrive name                        
##   &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;int&gt;    &lt;int&gt; &lt;chr&gt;                       
## 1 -6.08  145.     5282        5        5 Goroka Airport              
## 2 -5.21  146.       20        8        8 Madang Airport              
## 3 -5.83  144.     5388       10       12 Mount Hagen Kagamuga Airport
```

--

- The goal is to understand how the variable(s) (e.g., `altitude`) vary across different spatial locations

- Typically, the latitude and longitude are represented with dots, and the variable(s) are represented with size and/or colors

---

## Adding points to the map as usual

.pull-left[


```r
ggmap(map) +
* geom_point(data = airports,
             aes(x = lon, y = lat),
             alpha = 0.25)
```

- Display locations of airports using `geom_point()` layer, need to specify `data` for layer

- Currently viewing __point-pattern__ data 

]

.pull-right[
&lt;img src="figs/lec18/unnamed-chunk-19-1.png" width="100%" /&gt;

]


---

## Altering points on the map (in the usual way)

.pull-left[


```r
ggmap(map) +
  geom_point(data = airports, 
             aes(x = lon, y = lat, 
*                size = sqrt(n_depart),
*                color = sqrt(n_arrive)),
             alpha = .5) +
  scale_size_area(breaks = sqrt(c(1, 5, 10, 50, 100, 500)), 
                  labels = c(1, 5, 10, 50, 100, 500), 
                  name = "# departures") +
  scale_color_distiller(palette = "Spectral") +
  labs(color = "sqrt(# arrivals)") +
  theme(legend.position = "bottom")
```


- Displaying additional variables through `aes`


]

.pull-right[
&lt;img src="figs/lec18/unnamed-chunk-20-1.png" width="100%" /&gt;

]

---

## Inference for Spatial Data


There are whole courses, textbooks, and careers dedicated to this. We're not going to learn everything!


However, there are some straightforward analyses that can be done for spatial data.

We're going to focus on point-referenced (today) and areal data (Wednesday).


#### Point-Referenced Data

+ Divide geography into clusters (e.g., north/south/east/west) and use ANOVA to test if there are significant differences.

+ Regression of `\(\text{outcome} \sim \text{latitude} + \text{longitude}\)`. Smoothing regression (e.g., loess) is particularly useful here.

---

### Visualizations and Inference for Point-Reference Data

For basic linear regression:

1. Plot `\((x, y)\)` as points

2. Fit the regression model `\(y \sim x\)`, to give us  `\(\hat{y} = \hat{\beta}_0 + \hat{\beta}_1 \cdot x\)`

3. Plot `\((x, \hat{y})\)` as a line

--

For point reference data, we have the following variables:

+ longitude: `\(x\)`

+ latitude: `\(y\)`

+ Outcome variable: `\(z\)`

Consider the following linear regression model: `\(z \sim \text{lat} + \text{long}\)`

Goal: Make a visual involving `\((\text{long}, \text{lat}, \hat{z})\)`, and possibly `\(z\)`.

+ This is indeed the linear regression equivalent, which plots `\((x,y, \hat{y})\)`

---

## Kriging

Goal: Make a visual involving (long, lat, `\(\hat{z}\)`) and possibly `\(z\)`

Want `\(\hat{z}\)` for many (long, lat) combos (not just the observed one!)

To do this, follow this procedure:

1. Fit the model `\(z \sim \text{lat} + \text{long}\)`

2. Create a grid of `\((\text{long}, \text{lat})_{ij}\)`

3. Generate `\(\hat{z}_{ij}\)` for each `\((\text{long}, \text{lat})_{ij}\)`

4. Plot a heat map or contour plot of (long, lat, `\(\hat{z}\)`)

+ You can also add the actual `\(z\)` values (e.g., via size) on the heat map

#### This is known as _kriging_, or _spatial interpolation_

---

## Kriging: airline data example


&lt;img src="figs/lec18/unnamed-chunk-21-1.png" width="100%" style="display: block; margin: auto;" /&gt;

---

## Kriging: creating the map

&lt;img src="figs/lec18/unnamed-chunk-22-1.png" width="100%" style="display: block; margin: auto;" /&gt;


---

## Kriging: generating the grid


&lt;img src="figs/lec18/unnamed-chunk-23-1.png" width="100%" style="display: block; margin: auto;" /&gt;

---


## Kriging: generating predicted values


&lt;img src="figs/lec18/unnamed-chunk-24-1.png" width="100%" style="display: block; margin: auto;" /&gt;



---

## Kriging: plotting heat map of predicted values


&lt;img src="figs/lec18/final-kriging-1.png" width="100%" style="display: block; margin: auto;" /&gt;


---

## Lecture 18 Demo - Kriging

.pull-left[

The steps used to create this map are...

1. Fit an interactive regression model using `loess()`

2. Make a grid of lat/long coordinates, using `seq()` and `expand.grid()`

3. Get estimated outcomes across the grid using `predict()`

4. Use `geom_contour_filled()` to color map by estimated outcomes

]

.pull-right[

&lt;img src="figs/lec18/unnamed-chunk-25-1.png" width="100%" /&gt;


]


---

## Main Takeaways

#### Spatial data is most commonly encoded in a 2D plane (latitude/longitude), i.e., maps

#### Decisions to make: what projection to use? do we need all specific geolocations, or just general areas (e.g., states)?

#### What kind of data do we have?

* Point pattern: Scatterplots with density contours.

* Point-referenced: Scatterplots with color/size, use regression/loess for inference.

* Areal: See Wednesday...

#### Helpful to think carefully about the kind of data structure you need before starting to make visualizations

--

+ __HW7 is due Wednesday April 5th!__

+ __Graphics critique due April 7th!__

+ Review more code in Lecture 18 Demo! 


#### Next time: Areal data
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"slideNumberFormat": "%current%",
"highlightStyle": "github",
"highlightLines": true,
"ratio": "16:9",
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
