---
title: "36-315 Lecture 4"
subtitle: "Visualizing 1D Inference and 2D Categorical Data"  
author: 
  - "Professor Ron Yurko"
date: '1/30/2023'
output:
  xaringan::moon_reader:
    css: xaringan-themer.css
    lib_dir: libs
    nature:
      slideNumberFormat: "%current%"
      highlightStyle: github
      highlightLines: true
      ratio: 16:9
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(
  fig.width=9, fig.height=3.5, fig.retina=3,
  out.width = "100%",
  cache = FALSE,
  echo = TRUE,
  message = FALSE, 
  warning = FALSE,
  hiline = TRUE,
  fig.path = "figs/Lec4/"
)

xaringanExtra::use_clipboard()
```

```{r xaringan-themer, include=FALSE, warning=FALSE}
library(xaringanthemer)
style_duo_accent(
  primary_color = "#c41230",
  secondary_color = "#0277BD",
  inverse_header_color = "#FFFFFF"
)
```

```{r, include = FALSE, warning = FALSE}
library(tidyverse)
library(palmerpenguins)
```

## Conceptual Review

#### Last class - statistical inference for 1D categorical data

- Main estimators: $\underbrace{\hat{p}_1,\dots,\hat{p}_K}_{\text{proportions}}$ for $K$-many categories
  
- Chi-square test is the main statistical test for 1D categorical data, tests $H_0: p_1 = \cdots = p_K$
  
- Can also make confidence intervals for $\hat{p}_1,\dots,\hat{p}_K$ (to get CIs for $n_1,\dots,n_K$, multiply CIs by $n$)

--

#### Today

- Interpreting CIs on graphs is tricky and have to be careful with multiple testing
  
- Visuals for 2D categorical data

#### REMINDERS

- HW1 due Wednesday (11:59 PM) on Gradescope (OH @ 1:30 today and Wednesday in my office BH 132D!)
  
- HW2 is posted and due _next_ Wednesday

---

## Graphics versus Statistical Inference

- Reminder - Anscombe's Quartet: where statistical inference was the same but the graphics were very different

```{r, echo = FALSE, out.width="55%", fig.align='center'}
knitr::include_graphics("https://upload.wikimedia.org/wikipedia/commons/thumb/e/ec/Anscombe%27s_quartet_3.svg/1200px-Anscombe%27s_quartet_3.svg.png")
```


--

- __The opposite can be true!__ Graphics are the same, but statistical inference is very different...


---

### Example: 3 categories, $p_1 = 1/2,\ p_2 = p_3 = 1/4$

```{r, echo = FALSE, fig.align='center'}
fake_counts <- tibble(fake_group = c("A", "A", "B", "C"))
fake_counts %>%
  ggplot(aes(x = fake_group)) +
  geom_bar(fill = "darkblue") +
  theme_bw() +
  theme(axis.title = element_blank(),
        axis.text = element_text(size = 16))

```


---

### Example: 3 categories, $p_1 = 1/2,\ p_2 = p_3 = 1/4$

```{r low-count-noted-bars, echo = FALSE, fig.align='center'}
# Init the fake data
fake_counts <- tibble(fake_group = c("A", "A", "B", "C"))
# Run and store the chi-square test:
fake_chisq_test_results <- chisq.test(table(fake_counts$fake_group))
# Create the plot
fake_counts %>%
  ggplot(aes(x = fake_group)) +
  geom_bar(fill = "darkblue") +
  # Add the label with number of observations
  annotate(geom = "text", x = 2.5, y = 1.5, size = 5,
           label = paste0("n = ", nrow(fake_counts))) +
  # Add label with p-value from chi-square test
  annotate(geom = "text", x = 2.5, y = 1.25, size = 5,
           label = paste0("p-value = ", 
                          signif(fake_chisq_test_results$p.value,
                                 digits = 2))) +
  theme_bw() +
  theme(axis.title = element_blank(),
        axis.text = element_text(size = 16))

```


---

### Example: 3 categories, $p_1 = 1/2,\ p_2 = p_3 = 1/4$

```{r mid-count-noted-bars, echo = FALSE, fig.align='center'}
# Init the fake data
fake_counts <- tibble(fake_group = c(rep("A", 8), 
                                     rep("B", 4), rep("C", 4)))
# Run and store the chi-square test:
fake_chisq_test_results <- chisq.test(table(fake_counts$fake_group))
fake_counts %>%
  ggplot(aes(x = fake_group)) +
  geom_bar(fill = "darkblue") +
  # Add labels but preserve location of vertical label based on change in n
  annotate(geom = "text", x = 2.5, y = 1.5 * 8 / 2, size = 5,
           label = paste0("n = ", nrow(fake_counts))) +
  annotate(geom = "text", x = 2.5, y = 1.25 * 8 / 2, size = 5,
           label = paste0("p-value = ", 
                          signif(fake_chisq_test_results$p.value,
                                 digits = 2))) +
  theme_bw() +
  theme(axis.title = element_blank(),
        axis.text = element_text(size = 16))

```


---

### Example: 3 categories, $p_1 = 1/2,\ p_2 = p_3 = 1/4$

```{r high-count-noted-bars, echo = FALSE, fig.align='center'}
# Init the fake data
fake_counts <- tibble(fake_group = c(rep("A", 32), 
                                     rep("B", 16), rep("C", 16)))
# Run and store the chi-square test:
fake_chisq_test_results <- chisq.test(table(fake_counts$fake_group))
# Create the plot
fake_counts %>%
  ggplot(aes(x = fake_group)) +
  geom_bar(fill = "darkblue") +
  # Add labels but preserve location of vertical label based on change in n
  annotate(geom = "text", x = 2.5, y = 1.5 * 32 / 2, size = 5,
           label = paste0("n = ", nrow(fake_counts))) +
  annotate(geom = "text", x = 2.5, y = 1.25 * 32 / 2, size = 5,
           label = paste0("p-value = ", 
                          signif(fake_chisq_test_results$p.value,
                                 digits = 2))) +
  theme_bw() +
  theme(axis.title = element_blank(),
        axis.text = element_text(size = 16))

```


---

## Power under this scenario: (2n/4, n/4, n/4)

```{r chi-power-curve, echo = FALSE, fig.align='center'}
# Iterate through a sequence of sample sizes to compute the pvalue:
chisq_power_table <-
  map_dfr(seq(4, 100, by = 4),
          # Apply the following function to each value
          function(x) {
            
            # Init the fake data:
            fake_data <- tibble(fake_group = 
                                  c(rep("A", 2 * x / 4), 
                                    rep("B", x / 4), rep("C", x / 4)))
            
            # Run and store the chi-square test:
            fake_results <- chisq.test(table(fake_data$fake_group))
            
            # Return a table with the p-value and n:
            tibble("n" = x,
                   "pval" = fake_results$p.value)
          })

# Plot the results:
chisq_power_table %>%
  # Note the use of 
  ggplot(aes(x = n, y = pval)) +
  # Draw a line layer to connect the points 
  geom_line(color = "gray") +
  geom_point(color = "black") +
  # Add a horizontal line at 0.05:
  geom_hline(yintercept = 0.05, linetype = "dashed", 
             color = "red") +
  scale_x_continuous(breaks = seq(0, 100, by = 20)) +
  theme_bw() +
  labs(x = "Sample size", y = "p-value")

```


---

## How do we combine graphs with inference?

1. Simply add $p$-values (or other info) to graph via text

2. Add confidence intervals to the graph

  - Need to remember what each CI is for! 
  
  - Our CIs on previous slides are for each $\hat{p}_j$ marginally, __NOT__ jointly

  - Have to be careful with __multiple testing__...

---

## CIs will visually capture uncertainty in estimates

.pull-left[

```{r low-count-bars-se, echo = FALSE, fig.align='center', fig.height=7}
# Init the fake data
fake_counts <- tibble(fake_group = c("A", "A", "B", "C"))
# Compute the summary with standard errors:
fake_counts %>%
  group_by(fake_group) %>%
  summarize(count = n(), .groups = "drop") %>%
  mutate(total = sum(count),
         prop = count / total,
         se = sqrt(prop * (1 - prop) / total),
         lower = prop - 2 * se,
         upper = prop + 2 * se) %>%
  ggplot(aes(x = fake_group)) +
  geom_bar(fill = "darkblue",
           aes(y = prop),
           stat = "identity") +
  geom_errorbar(aes(ymin = lower,
                    ymax = upper),
                color = "red") +
  # Add the label with number of observations
  annotate(geom = "text", x = 2.5, y = .75, size = 10,
           label = paste0("n = ", nrow(fake_counts))) +
  theme_bw() +
  theme(axis.title = element_blank(),
        axis.text = element_text(size = 16))

```

]
.pull-right[

```{r high-count-bars-se, echo = FALSE, fig.align='center', fig.height = 7}
# Init the fake data
fake_counts <- tibble(fake_group = c(rep("A", 32), 
                                     rep("B", 16), rep("C", 16)))# Compute the summary with standard errors:
fake_counts %>%
  group_by(fake_group) %>%
  summarize(count = n(), .groups = "drop") %>%
  mutate(total = sum(count),
         prop = count / total,
         se = sqrt(prop * (1 - prop) / total),
         lower = prop - 2 * se,
         upper = prop + 2 * se) %>%
  ggplot(aes(x = fake_group)) +
  geom_bar(fill = "darkblue",
           aes(y = prop),
           stat = "identity") +
  geom_errorbar(aes(ymin = lower,
                    ymax = upper),
                color = "red") +
  # Add the label with number of observations
  annotate(geom = "text", x = 2.5, y = .75, size = 10,
           label = paste0("n = ", nrow(fake_counts))) +
  scale_y_continuous(limits = c(0, 1)) +
  theme_bw() +
  theme(axis.title = element_blank(),
        axis.text = element_text(size = 16))

```

]

---

## (Rough) Rules-of-thumb for comparing CIs on bar charts

- Comparing overlap of two CIs is __NOT__ exactly the same as directly testing for a significant difference...

  - Really you want CI( $\hat{p}_1 - \hat{p}_2$ ), not CI( $\hat{p_1}$ ) and CI( $\hat{p_2}$ )
  
  - CI( $\hat{p_1}$ ) and CI( $\hat{p_2}$ ) not overlapping implies $0 \notin$ CI( $\hat{p}_1 - \hat{p}_2$ )
  
--

  - _However_ CI( $\hat{p_1}$ ) and CI( $\hat{p_2}$ ) overlapping __DOES NOT__ imply $0 \in$ CI( $\hat{p}_1 - \hat{p}_2$ ) 


--

Roughly speaking:

  - If CIs don't overlap $\rightarrow$ significant difference
  
  - If CIs overlap a little $\rightarrow$ ambiguous
  
  - If CIs overlap a lot $\rightarrow$ no significant difference
  
--

But if we're comparing more than two CIs simultaneously, we need to account for __multiple testing__!

  - When you look for all non-overlapping CIs: implicitly making $\binom{K}{2} = \frac{K!}{2!(K-2)!}$ pairwise tests in your head!
  

---

## Corrections for multiple testing (and visualizing them)

- In those bar plots, when we determine whether CIs overlap we make 3 comparisons:

  1. A vs B
  
  2. A vs C
  
  3. B vs C
  
#### This is a multiple testing issue

--

- In short: we will make Type 1 errors (chance of false rejecting) more than 5% of the time!

- Reminder: Type 1 error = Rejecting $H_0$ when $H_0$ is true

- e.g., CIs don't overlap but actually $H_0: p_A = p_B$ is true
  
- If only interested in A vs B __and nothing else__, then just construct 95% CI for A vs B and _control error rate_ at 5%
  
- However, if we construct several CIs, where A vs B is just one comparison we make, our Type 1 error rate > 5%!

---

## Corrections for multiple testing (and visualizing them)

Vast literature on corrections for multiple testing (beyond the scope of this class... but in my thesis!)

- But you should understand the following:

1. Corrections for multiple testing inflate $p$-values (i.e., make them bigger)

2. Equivalently, they inflate CIs (i.e., make them wider)

3. Purpose of these corrections is to control Type 1 error rate $\leq 5\%$

--

We'll focus on the __Bonferroni correction__, which inflates $p$-values the most but is easy to implement and very popular:

+ We usually reject null hypothesis when $p$-value $\leq .05$

+ __Bonferroni__: if making $K$ comparisons, reject only if $p$-value $\leq .05/K$

--

+ For CIs: instead of plotting 95% CIs, we plot (1 - $0.05/K$)% CIs

  + e.g., for $K = 3$ then plot 98.3% CIs
  
---

## Impact of Bonferroni correction on CIs...

.pull-left[
```{r ref.label="high-count-bars-se", eval = TRUE, echo = FALSE, fig.align='center', fig.height = 7}

```
]
.pull-right[

```{r larger-intervals, echo = FALSE, fig.align='center', fig.height = 7}
# Init the fake data
fake_counts <- tibble(fake_group = c(rep("A", 32), 
                                     rep("B", 16), rep("C", 16)))# Compute the summary with standard errors:
fake_counts %>%
  group_by(fake_group) %>%
  summarize(count = n(), .groups = "drop") %>%
  mutate(total = sum(count),
         prop = count / total,
         se = sqrt(prop * (1 - prop) / total),
         lower = prop - qnorm(1 - .05 / 3 / 2) * se,
         upper = prop + qnorm(1 - .05 / 3 / 2) * se) %>%
  ggplot(aes(x = fake_group)) +
  geom_bar(fill = "darkblue",
           aes(y = prop),
           stat = "identity") +
  geom_errorbar(aes(ymin = lower,
                    ymax = upper),
                color = "red") +
  # Add the label with number of observations
  annotate(geom = "text", x = 2.5, y = .75, size = 10,
           label = paste0("n = ", nrow(fake_counts))) +
  scale_y_continuous(limits = c(0, 1)) +
  theme_bw() +
  theme(axis.title = element_blank(),
        axis.text = element_text(size = 16))

```

]


---

## 2D categorical basics: marginal / conditional distribution 



---

## 2D categorical basics: marginal / conditional distribution 

```{r, warning = FALSE, message = FALSE, fig.align='center'}
addmargins(table("Species" = penguins$species, "Island" = penguins$island))
```

- Column and row sums: marginal distributions 

- Values within rows: conditional distribution for `Island` given `Species`

- Values within columns: conditional distribution for `Species` given `Island` 

- Bottom right: total number of observations 

---

## Connecting distributions to visualizations

There are five distributions we may care about for two categorical variables $A$ and $B$:

- __Marginals__:  $P(A)$ and $P(B)$

- __Conditionals__: $P(A | B)$ and $P(B|A)$

- __Joint__: $P(A, B)$

--

We use bar charts to visualize marginal distributions for categorical variables

__How can we visualize the conditionals and joint distributions?__

--

Naive approaches to visualize:

- Different conditionals, e.g., $P(A|B = b_1)$, $P(A | B = b_2)$, ..., could make a bar chart for each $b_1, b_2,...$

- Joint distribution, could create a bar for each combination of $A$ and $B$

We'll effectively make tweaks of these with __stacked__ and __side-by-side__ bar charts

---

## Stacked bar plots - a bar chart of spine charts

.pull-left[


```{r stacked-bar, fig.show = 'hide'}
penguins %>%
  ggplot(aes(x = species,
             fill = island)) + #<<
  geom_bar() + 
  theme_bw()
```

- Easy to see marginal of `species`

  - i.e., $P($ `x` $)$

- Can see conditional of `island` | `species` 

  - i.e., $P($ `fill` | `x` $)$

- Harder to see conditional of `species` | `island`

  - i.e., $P($ `x` | `fill` $)$

]

.pull-right[

```{r ref.label = 'stacked-bar', echo = FALSE, fig.width=5, fig.height=4}
```

]

---

## Side-by-side bar plots

.pull-left[


```{r side-bar, fig.show = 'hide'}
penguins %>%
  ggplot(aes(x = species,
             fill = island)) + 
  geom_bar(position = "dodge") + #<<
  theme_bw()
```

- Use `position = "dodge"` to move bars side-by-side (this applies to other visualizations also)

- Notice that some bars are dropped...

]

.pull-right[

```{r ref.label = 'side-bar', echo = FALSE, fig.width=5, fig.height=4}
```

]


---

## Side-by-side bar plots

.pull-left[


```{r side-bar-upd, fig.show = 'hide'}
penguins %>%
  ggplot(aes(x = species,
             fill = island)) + 
  geom_bar(position = 
           position_dodge(preserve = "single")) + #<<
  theme_bw()
```

- Easy to see conditional of `island` | `species`

  - i.e., $P($ `fill` | `x` $)$

- Can see conditional of `species` | `island` 

  - i.e., $P($ `x` | `fill` $)$

- Hard to see marginals...
  
__What else do we see?__

]

.pull-right[

```{r ref.label = 'side-bar-upd', echo = FALSE, fig.width=5, fig.height=4}
```

]

---

## Side-by-side bar plots (dodge2)

.pull-left[


```{r side-bar-upd2, fig.show = 'hide'}
penguins %>%
  ggplot(aes(x = species,
             fill = island)) + 
  geom_bar(position = 
           position_dodge2(preserve = "single")) + #<<
  theme_bw()
```

- [Another way to center bars](https://ggplot2.tidyverse.org/reference/position_dodge.html)

- Easy to see conditional of `island` | `species`

  - i.e., $P($ `fill` | `x` $)$

- Can see conditional of `species` | `island` 

  - i.e., $P($ `x` | `fill` $)$

]

.pull-right[

```{r ref.label = 'side-bar-upd2', echo = FALSE, fig.width=5, fig.height=4}
```

]

---

## What do you prefer?

.pull-left[

```{r ref.label = 'stacked-bar', echo = FALSE, fig.width=5, fig.height=4}
```

]

.pull-right[

```{r ref.label = 'side-bar-upd2', echo = FALSE, fig.width=5, fig.height=4}
```


]

---
class: center, middle

# Next time: Visualizing inference for 2D categorical data

Reminder: __HW1 due Wednesday!__ HW2 posted and due next week...

Recommended reading: 

[CW Chapter 11 Visualizing nested proportions](https://clauswilke.com/dataviz/nested-proportions.html)