---
title: "36-315 Lecture 10"
subtitle: "2D Quantitative Data: Scatterplots and Linear Regression"  
author: 
  - "Professor Ron Yurko"
date: '2/20/2023'
output:
  xaringan::moon_reader:
    css: xaringan-themer.css
    lib_dir: libs
    nature:
      slideNumberFormat: "%current%"
      highlightStyle: github
      highlightLines: true
      ratio: 16:9
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(
  fig.width=9, fig.height=3.5, fig.retina=3,
  out.width = "100%",
  cache = FALSE,
  echo = TRUE,
  message = FALSE, 
  warning = FALSE,
  hiline = TRUE,
  fig.path = "figs/Lec10/"
)

xaringanExtra::use_clipboard()
```

```{r xaringan-themer, include=FALSE, warning=FALSE}
library(xaringanthemer)
style_duo_accent(
  primary_color = "#c41230",
  secondary_color = "#0277BD",
  inverse_header_color = "#FFFFFF"
)
```


```{r, include = FALSE}
library(tidyverse)
library(palmerpenguins)
```


## Let's talk about the take-home exam

* Here's the timeline for the next two weeks:

  + __HW4 is due Wednesday Feb 22nd at 11:59 PM EDT!__
  
  + __Take-home exam is next week Wednesday March 1st__
  
* Here's how the exam will work:

  + I'll post the exam Tuesday evening, and it's due Wednesday by 11:59 PM EDT (March 1st)
  
  + Exam will cover material from homeworks 1-4 and labs 1-6
  
  + Questions will be similar to homeworks but more open-ended, e.g, instead of "make a side-by-side boxplot..." I'll ask "Make a plot that compares the conditional distributions..."
  
  + __There will NOT be class on Wednesday March 1st__ - instead I will hold office hours during the class time for clarifying questions about the exam. __This will be over zoom with one-on-one interactions via Waiting Room feature__
  
  + Conflict March 1st? __Let me know ASAP!__ Day-of accomodations won't be made, late submissions will NOT be accepted
  
---

## Conceptual Review

We've seen 1D and 2D categorical data, and 1D quantitative data combined with categorical data

* Mosaicplots: Great for visualizing inference for 2D categorical data

* Facetted histograms, side-by-side violins, overlayed densities: Great for comparing subsets of 1D quantitative data


Several ways to formally compare distributions:

* $t$-test: Compare means

* Bartlett's test: Compare variances

* KS test: Compare distributions

Statistical power (probability of correctly rejecting the null) is important when interpreting graphs and analyses

__Today: 2D quantitative data, scatterplots, and linear regression__ 

---

## 2D quantitative data

- We're working with two variables: $(X, Y) \in \mathbb{R}^2$, i.e., dataset with $n$ rows and 2 columns

--

- Goals:

  - describing the relationships between two variables
  
  - describing the conditional distribution $Y | X$ via regression analysis
  
  - describing the joint distribution $X,Y$ via contours, heatmaps, etc.
  
--

- Few big picture ideas to keep in mind:

  - scatterplots are by far the most common visual
  
  - regression analysis is by far the most popular analysis (you will have several classes on this...)
  
  - there are many types of nonlinear relationships
  
  - relationships may vary across other variables, e.g., categorical variables
  
---

## Making scatterplots with `geom_point()`

.pull-left[


```{r start-plot, eval = FALSE}
penguins %>%
  ggplot(aes(x = bill_depth_mm, 
             y = bill_length_mm)) +
  geom_point() #<<
```

- Displaying the joint distribution

- What is the __obvious flaw__ with this plot?

]

.pull-right[

```{r ref.label="start-plot", echo = FALSE, fig.height=7}
```

]


---

## Making scatterplots: ALWAYS adjust the `alpha`

.pull-left[


```{r alpha-plot, eval = FALSE}
penguins %>%
  ggplot(aes(x = bill_depth_mm, 
             y = bill_length_mm)) +
  geom_point(alpha = 0.5) #<<
```

- Adjust the transparency of points via `alpha` to __visualize overlap__ 

- Provides better understanding of joint frequency

- Especially important with larger datasets



]

.pull-right[

```{r ref.label="alpha-plot", echo = FALSE, fig.height=7}
```

]

---

## Making scatterplots: map categorical variable to `color`


```{r, fig.align='center', fig.height=3}
ggplot(penguins, aes(x = bill_depth_mm, y = bill_length_mm,
                     color = species)) + #<<
  geom_point(alpha = 0.5) 
```

---

## Making scatterplots: map continuous variable to `color`


```{r, fig.align='center', fig.height=3}
ggplot(penguins, aes(x = bill_depth_mm, y = bill_length_mm,
                     color = body_mass_g)) + #<<
  geom_point(alpha = 0.5) 
```


---

## Making scatterplots: map continuous variable to `color`


```{r, fig.align='center', fig.height=3}
ggplot(penguins, aes(x = bill_depth_mm, y = bill_length_mm,
                     color = body_mass_g)) +
  geom_point(alpha = 0.5) +
  scale_color_gradient(low = "darkblue", high = "darkorange") #<<
```


---

## Making scatterplots: map continuous variable to `size`


```{r, fig.align='center', fig.height=3}
ggplot(penguins, aes(x = bill_depth_mm, y = bill_length_mm,
                     size = body_mass_g)) + #<<
  geom_point(alpha = 0.5) 
```

---

## Making scatterplots: map categorical variable to `shape`


```{r, fig.align='center', fig.height=3}
ggplot(penguins, aes(x = bill_depth_mm, y = bill_length_mm,
                     shape = species)) + #<<
  geom_point(alpha = 0.5) 
```


---

## Making scatterplots: ALL AT ONCE!


.pull-left[
```{r all-plot, eval = FALSE}
penguins %>%
  ggplot(aes(x = bill_depth_mm, 
             y = bill_length_mm,
             color = species, #<<
             shape = island, #<< 
             size = body_mass_g)) + #<<
  geom_point(alpha = 0.5) 
```

- 5 dimensions at once!

- But we should be careful about this...

]
.pull-right[
```{r, ref.label='all-plot', echo = FALSE, fig.height = 7}

```

]



---

```{r, echo = FALSE, fig.align='center'}
knitr::include_graphics("https://images.squarespace-cdn.com/content/v1/5ce45e9df03bfe000172d138/1597870238202-3OWP5306LOI8P2HP02EN/Jeff+Goldblum+Your+Scientists+Were+so+preoccupied+with+whether+or+not+they+could+they+didn%27t+stop+to+think+if+they+should.jpg")
```


---

## Displaying trend lines: linear regression

.pull-left[

```{r line-plot, eval = FALSE}
penguins %>%
  ggplot(aes(x = flipper_length_mm, 
             y = body_mass_g)) +
  geom_point(alpha = 0.5) + 
  geom_smooth(method = "lm") #<<
```

- Displays `body_mass_g ~ flipper_length_mm` regression line

- Adds 95% confidence intervals by default

- Estimating the __conditional expectation__ of `body_mass_g` | `flipper_length_mm`, 

  - i.e., $\mathbb{E}[Y | X]$


]
.pull-right[

```{r ref.label="line-plot", echo = FALSE, fig.height=7}

```


]

---

## Setup and motivation for linear regression

Consider an outcome $Y \in \mathbb{R}$ and covariate $X \in \mathbb{R}$

  + We have $n$ observations: $(X_1, Y_1), \dots, (X_n, Y_n)$
  
Purpose of regression is to model $\mathbb{E}[Y | X]$

--

Consider the case where $X$ takes on discrete values $c_1, \dots, c_k$

Then most straightforward way to estimate $\mathbb{E}[Y | X = c_j]$ is to use the sample mean for subgroup $X_i = c_j$:

$$\hat{\mathbb{E}}[Y|X = c_j] = \frac{1}{N_j} \sum_{i: X_i = c_j} Y_i$$

+ Graphs like side-by-side violin plots, facetted histograms, and overlaid density plots essentially compare $\hat{\mathbb{E}}[Y|X = c_j]$ for different categories

But when $X$ is quantitative, what do we do?

+ Use statistical model to "guess" what $\mathbb{E}[Y|X = x]$ is, even when we don't observe $X = x$

---

## Statistical Model for Linear Regression

Linear regression assumes $Y_i \overset{iid}{\sim} N(\beta_0 + \beta_1 X_i, \sigma^2)$

- $\beta_0$: _intercept_ - population mean outcome when $X = 0$; i.e., $\mathbb{E}[Y | X = 0]$

- $\beta_1$: _slope_ - population mean _change_ in $Y$ when $X$ increases by 1

- $\beta_0$ and $\beta_1$ are parameters that must be estimated

--

The assumptions baked into this model are:

1. Normality

2. Equal variance

3. Independent errors

4. Linearity

5. Fixed $X$


---

## Assessing assumptions of linear regression

Linear regression assumes $Y_i \overset{iid}{\sim} N(\beta_0 + \beta_1 X_i, \sigma^2)$

- If this is true, then $Y_i - \hat{Y}_i \overset{iid}{\sim} N(0, \sigma^2)$

--

Plot residuals against $\hat{Y}_i$, __residuals vs fit__ plot

- Used to assess linearity, any divergence from mean 0

- Used to assess equal variance, i.e., if $\sigma^2$ is homogenous across predictions/fits $\hat{Y}_i$

--

More difficult to assess the independence and fixed $X$ assumptions

- Make these assumptions based on subject-matter knowledge

---

## Residual vs fit plots

.pull-left[

```{r resid-plot, eval = FALSE}
lin_reg <- 
  lm(body_mass_g ~ flipper_length_mm, #<<
     data = penguins)

tibble(fits = fitted(lin_reg), 
       residuals = residuals(lin_reg)) %>%
  ggplot(aes(x = fits, y = residuals)) +
  geom_point(alpha = 0.5) +
  geom_hline(yintercept = 0, #<<
             linetype = "dashed", #<<
             color = "red")
```

Two things to look for:

1. Any trend around horizontal reference line?

2. Equal vertical spread?

]

.pull-right[

```{r ref.label="resid-plot", echo = FALSE, fig.height=7}

```


]

---

## Residual vs fit plots

.pull-left[

```{r resid-upd-plot, eval = FALSE}
tibble(fits = fitted(lin_reg), 
       residuals = residuals(lin_reg)) %>%
  ggplot(aes(x = fits, y = residuals)) +
  geom_point(alpha = 0.5) +
  geom_hline(yintercept = 0, 
             linetype = "dashed",
             color = "red") +
  geom_smooth() #<<
```

Two things to look for:

1. Any trend around horizontal reference line? 

  - add `geom_smooth` to highlight this

2. Equal vertical spread?

]

.pull-right[

```{r ref.label="resid-upd-plot", echo = FALSE, fig.height=7}

```


]

---

## Examples of Residual-vs-Fit Plots



---

## Main Takeaways

#### Scatterplots are the most common visual for 2D quantitative variables

+ Many ways to incorporate additional dimensions in scatterplots, e.g., color and shape

+ Allows you to assess if the relationship between $X_1$ and $X_2$ depends on other variables

Linear regression is by far the most common model for describing the relationship between 2+ quantitative variables

+ Can also transform the outcome

+ Can also transform the covariates

+ Can also do nonparametric "smoothing"

#### Use graphs to assess linear regression assumptions

---
class: center, middle

# Next time: Inference with Linear Regression

Reminder: __HW4 due Wednesday!__  __Graphics critique due Feb 28th!__

Recommended reading: 

[CW Chapter 12 Visualizing associations among two or more quantitative variables](https://clauswilke.com/dataviz/visualizing-associations.html)


